{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec105c8-8f17-43f4-b00a-414f5c807135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbf1799-5d19-424e-aaa4-ce14537e0187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 4 oof files...\n",
      "\n",
      "['oof_df_rbc.pkl' 'oof_df_rbcs.pkl' 'oof_df_rucola.pkl' 'oof_df_sbert.pkl']\n"
     ]
    }
   ],
   "source": [
    "PATH = 'oofs/'\n",
    "FILES = os.listdir(PATH)\n",
    "\n",
    "OOF = np.sort( [f for f in FILES if 'pkl' in f] )\n",
    "OOF_CSV = [pd.read_pickle(PATH+k).sort_values(by=['oid']) for k in OOF]\n",
    "\n",
    "print('We have %i oof files...'%len(OOF))\n",
    "print(); print(OOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5b6a0a-5f12-4dc5-9f71-30e7ccd62426",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(( len(OOF_CSV[0]),len(OOF), 13 ))\n",
    "y = np.zeros(( len(OOF_CSV[0]),len(OOF)))\n",
    "models = {}\n",
    "for k in range(len(OOF)):\n",
    "    models[k] = OOF[k]\n",
    "    for i in range(13):\n",
    "        x[:, k, i] = OOF_CSV[k][f\"pred_{i}\"].values\n",
    "    y[:,k] = OOF_CSV[k][\"category\"].values\n",
    "    \n",
    "x = softmax(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd28ffa-1785-453d-afd5-dcdbf4d2d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y_trues, y_preds):\n",
    "    y_preds = np.argmax(y_preds, axis=-1)\n",
    "    counter = 0\n",
    "    for tr, pr in zip(y_trues, y_preds):\n",
    "        if tr == pr:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter -= 1\n",
    "    metric = counter / len(y_trues)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a2061b-c9c3-4041-9a34-7e3589a28de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model oof_df_rbc.pkl has OOF MCRMSE = 0.7580\n",
      "Model oof_df_rbcs.pkl has OOF MCRMSE = 0.7436\n",
      "Model oof_df_rucola.pkl has OOF MCRMSE = 0.7612\n",
      "Model oof_df_sbert.pkl has OOF MCRMSE = 0.7637\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "for k in range(x.shape[1]): # по моделям\n",
    "    score = custom_score(y[:, k], x[:, k, :])\n",
    "    all.append(score)\n",
    "    print('Model %s has OOF score = %.4f'%(models[k], score))\n",
    "    \n",
    "m = [np.argmax(all)]; w = [] # argmin потому что с наименьшего скора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3bfd3fe-427a-4507-828f-26f05e863bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = np.max(all);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe47cec-67da-427c-9f0d-1c3b2c396d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = 1000; \n",
    "PATIENCE = 1000; \n",
    "TOL = 0.000\n",
    "DUPLICATES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f573b0-6268-4379-b9b9-19082700fa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble custom_metric = 0.7637 by beginning with model 3 oof_df_sbert.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Ensemble custom_metric = %.4f by beginning with model %i %s'%(old,m[0], models[m[0]]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82c3ab9-71aa-4b00-a1b3-349842c9ff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for best model to add... \n",
      "0 , 0.7939996070837192\n",
      "1 , 0.7876568156941989\n",
      "2 , 0.7910246695293425\n",
      "3 , \n",
      "Ensemble score = 0.7940 after adding model 0 with weight 0.501. Increase of 0.0303\n",
      "\n",
      "Searching for best model to add... \n",
      "0 , 1 , 0.7942802615699812\n",
      "2 , 0.8028682888495973\n",
      "3 , \n",
      "Ensemble score = 0.8029 after adding model 2 with weight 0.305. Increase of 0.0089\n",
      "\n",
      "Searching for best model to add... \n",
      "0 , 1 , 0.8033734669248688\n",
      "2 , 3 , \n",
      "Ensemble score = 0.8034 after adding model 1 with weight 0.053. Increase of 0.0005\n",
      "\n",
      "Searching for best model to add... \n",
      "0 , 1 , 2 , 3 , \n",
      "No increase. Stopping.\n"
     ]
    }
   ],
   "source": [
    "for kk in range(len(OOF)):\n",
    "    \n",
    "    # BUILD CURRENT ENSEMBLE\n",
    "    md = x[:, m[0], :]\n",
    "    # print(md.shape)\n",
    "    for i,k in enumerate(m[1:]):\n",
    "        md = w[i]*x[:,k] + (1-w[i])*md\n",
    "        \n",
    "    # FIND MODEL TO ADD\n",
    "    mx = 0; mx_k = 0; mx_w = 0\n",
    "    print('Searching for best model to add... ')\n",
    "    \n",
    "    # TRY ADDING EACH MODEL\n",
    "    for k in range(x.shape[1]): # по моделям\n",
    "        print(k,', ',end='')\n",
    "        if not DUPLICATES and (k in m): continue\n",
    "            \n",
    "        # EVALUATE ADDING MODEL K WITH WEIGHTS W\n",
    "        bst_j = 0; bst = 0; ct = 0\n",
    "        for j in range(RES): # по порогу\n",
    "            tmp = j/RES * x[:, k, :] + (1-j/RES) * md\n",
    "            score = custom_score(y[:, k], tmp)\n",
    "            if score>bst:\n",
    "                bst = score\n",
    "                bst_j = j/RES\n",
    "            else: ct += 1\n",
    "            if ct>PATIENCE: break\n",
    "        print(bst)\n",
    "        if bst>mx:\n",
    "            mx = bst\n",
    "            mx_k = k\n",
    "            mx_w = bst_j\n",
    "            \n",
    "    # STOP IF INCREASE IS LESS THAN TOL\n",
    "    inc = mx-old\n",
    "    if inc<=TOL: \n",
    "        print(); print('No increase. Stopping.')\n",
    "        break\n",
    "        \n",
    "    # DISPLAY RESULTS\n",
    "    print();\n",
    "    print('Ensemble score = %.4f after adding model %i with weight %.3f. Increase of %.4f'%(mx,mx_k,mx_w,inc))\n",
    "    print()\n",
    "    \n",
    "    old = mx; m.append(mx_k); w.append(mx_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102e2825-5742-4a46-932e-0c59fbcf9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(weights):\n",
    "    weights_copy = weights.copy()\n",
    "    for i, w_i in enumerate(weights[:-1]):\n",
    "        for w_j in weights_copy[i+1:]:\n",
    "            weights[i] *= 1 - w_j\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f3134e0-9a73-4443-a615-9d09407d3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = foo([1]+w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd583e4-ee38-4409-89bd-280b7cc168cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using models ['3_oof_df_sbert.pkl', '0_oof_df_rbc.pkl', '2_oof_df_rucola.pkl', '1_oof_df_rbcs.pkl']\n",
      "with weights [0.328424335, 0.329740665, 0.28883499999999995, 0.053]\n",
      "and achieve ensemble score = 0.8034\n"
     ]
    }
   ],
   "source": [
    "print('We are using models',list(map(lambda x: str(x)+ \"_\" +models[x], m)))\n",
    "print('with weights',w)\n",
    "print('and achieve ensemble score = %.4f'%old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344b543e-6904-48b2-b9fb-230f98647c1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7cf3ff9483f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a018c4491fcf>\u001b[0m in \u001b[0;36mcustom_score\u001b[0;34m(y_trues, y_preds)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_trues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Проверка\n",
    "x_all = np.zeros(x[:,0].shape)\n",
    "for model, weight in zip(m, w):\n",
    "    x_all += x[:, model] * weight\n",
    "    \n",
    "print(custom_score(x_all, y[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f68276-71c6-4a88-ae7c-4ddac1711a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
